# ğŸ“š Library Assistant RAG

A fully local **Retrieval-Augmented Generation (RAG)** application built using **Streamlit**, **ChromaDB**, **Sentence Transformers**, and **Ollama**.  
The system answers user queries strictly based on a curated library dataset containing book and chapter summaries.

---

## ğŸš€ Features
- Local semantic search using ChromaDB
- Embeddings with `all-MiniLM-L6-v2`
- Local LLM inference using Ollama (`llama3`)
- Streamlit-based chat interface
- Fully offline after setup (no cloud APIs)

---

## ğŸ—‚ï¸ Project Structure

```
Library-Assistant-RAG/
â”‚
â”œâ”€â”€ app.py                  # Streamlit RAG application
â”œâ”€â”€ build_index.py          # Script to create embeddings & vector index
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore              # Ignored files and folders
â”œâ”€â”€ README.md               # Project documentation
â”‚
â”œâ”€â”€ data/                   # Library dataset (JSON files)
â”‚   â”œâ”€â”€ Statistics Data.json
â”‚   â”œâ”€â”€ Machine Learning and Statistics Data.json
â”‚   â”œâ”€â”€ Management Data.json
â”‚   â”œâ”€â”€ Political Science Data.json
â”‚   â””â”€â”€ Computer Science Data.json
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/iidevanshiii/Library-Assistant-RAG.git
cd Library-Assistant-RAG
```

### 2ï¸âƒ£ Install Python Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ§  Install and Run Ollama

Download Ollama from:
https://ollama.com

Pull the required model:
```bash
ollama pull llama3
```

Ensure Ollama is running in the background before starting the app.

---

## ğŸ§© Build the Vector Index

Run this once to generate embeddings and store them in ChromaDB:
```bash
python build_index.py
```

---

## ğŸ’¬ Run the Application

```bash
streamlit run app.py
```

---

## ğŸ“Œ Notes
- The `db/` folder is auto-generated and should not be committed.
- Answers are generated **only from retrieved context** (true RAG behavior).
- Works completely offline after initial setup.

---

## ğŸ¯ Use Cases
- Library or academic search assistant
- NLP / RAG learning project
- Capstone project

---

## ğŸ‘©â€ğŸ’» Author
**Devanshi Sharma**

---

## ğŸ“„ License
MIT License
